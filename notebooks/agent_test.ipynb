{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "from typing import TypedDict, Optional\n",
    "from PIL import Image\n",
    "from ultralytics import YOLO\n",
    "from transformers import CLIPProcessor, CLIPModel\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "import json\n",
    "\n",
    "from src.utils.path import from_root\n",
    "from src.yolo.yolo import Yolo\n",
    "from src.llm_caller import LLMCaller\n",
    "from src.llm_detector import Detector\n",
    "from src.edge_validator import EdgeValidator\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working directory set to: /Users/emilstausbol/Documents/GitHub/AIML25-Exam\n"
     ]
    }
   ],
   "source": [
    "# === Ensure working directory is project root ===\n",
    "while Path.cwd().name.lower() != \"aiml25-exam\" and \"aiml25-exam\" in str(Path.cwd()).lower():\n",
    "    os.chdir(\"..\")\n",
    "print(f\"Working directory set to: {Path.cwd()}\")\n",
    "\n",
    "# === Initialize models ===\n",
    "yolo = Yolo(YOLO(from_root(\"models/yolo-trained.pt\")))\n",
    "llm = LLMCaller(\n",
    "    api_key=os.getenv(\"WX_API_KEY\"),\n",
    "    project_id=os.getenv(\"WX_PROJECT_ID\"),\n",
    "    api_url=\"https://us-south.ml.cloud.ibm.com\",\n",
    "    model_id=\"watsonx/meta-llama/llama-3-2-90b-vision-instruct\",\n",
    "    params={}\n",
    ")\n",
    "detector = Detector(llm, yolo)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === State ===\n",
    "class ImageState(TypedDict):\n",
    "    image_path: str\n",
    "    verbose: bool\n",
    "    is_diagram: Optional[bool]\n",
    "    classification_confidence: Optional[float]\n",
    "    diagram_detections: Optional[list]\n",
    "    cropped_images: Optional[list[str]]\n",
    "    graph: Optional[object]\n",
    "    validation_results: Optional[object]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Nodes ===\n",
    "def read_image(state: ImageState):\n",
    "    if state[\"verbose\"]:\n",
    "        print(f\"🔍 Reading image: {state['image_path']}\")\n",
    "    return {}\n",
    "\n",
    "def classify_image(state: ImageState):\n",
    "    model = CLIPModel.from_pretrained(\"openai/clip-vit-base-patch32\")\n",
    "    processor = CLIPProcessor.from_pretrained(\"openai/clip-vit-base-patch32\")\n",
    "    image = Image.open(state[\"image_path\"]).convert(\"RGB\")\n",
    "    inputs = processor(text=[\"a diagram\", \"not a diagram\"], images=image, return_tensors=\"pt\", padding=True)\n",
    "    outputs = model(**inputs)\n",
    "    probs = outputs.logits_per_image.softmax(dim=1)\n",
    "    is_diagram = probs.argmax().item() == 0\n",
    "    confidence = probs.max().item()\n",
    "    if state[\"verbose\"]:\n",
    "        print(f\"🧠 Image classification: {'Diagram' if is_diagram else 'Not a diagram'} (confidence: {confidence:.2f})\")\n",
    "    return {\"is_diagram\": is_diagram, \"classification_confidence\": confidence}\n",
    "\n",
    "def route_decision(state: ImageState) -> str:\n",
    "    return \"run_yolo_detection\" if state[\"is_diagram\"] else \"handle_non_diagram\"\n",
    "\n",
    "def handle_non_diagram(state: ImageState):\n",
    "    print(\"🚫 Not a diagram. Ending pipeline.\")\n",
    "    return {}\n",
    "\n",
    "def run_yolo_detection(state: ImageState):\n",
    "    if state[\"verbose\"]:\n",
    "        print(\"📦 Running YOLO detection...\")\n",
    "    yolo.predict(state[\"image_path\"])\n",
    "    detections = yolo.getBBoxes()\n",
    "\n",
    "    # 🔁 Fix: normalize keys for downstream steps\n",
    "    for det in detections:\n",
    "        det[\"coords\"] = det.pop(\"xyxy\")\n",
    "\n",
    "    return {\"diagram_detections\": detections}\n",
    "\n",
    "def crop_diagram(state: ImageState):\n",
    "    if state[\"verbose\"]:\n",
    "        print(\"✂️ Cropping diagram parts...\")\n",
    "    detections = state.get(\"diagram_detections\", [])\n",
    "    os.makedirs(\"tmp\", exist_ok=True)\n",
    "    image = Image.open(state[\"image_path\"]).convert(\"RGB\")\n",
    "    image_paths = []\n",
    "    for idx, det in enumerate(detections):\n",
    "        x1, y1, x2, y2 = map(int, det[\"coords\"])\n",
    "        cropped = image.crop((x1, y1, x2, y2))\n",
    "        path = f\"tmp/cropped_{idx+1}.png\"\n",
    "        cropped.save(path)\n",
    "        image_paths.append(path)\n",
    "        if state[\"verbose\"]:\n",
    "            print(f\"💾 Saved: {path}\")\n",
    "    return {\"cropped_images\": image_paths}\n",
    "\n",
    "def detect_nodes(state: ImageState):\n",
    "    if state[\"verbose\"]:\n",
    "        print(\"🔍 Detecting nodes...\")\n",
    "    detector.initiate_image(state[\"image_path\"])\n",
    "    detector.detect_nodes()\n",
    "    return {}\n",
    "\n",
    "def detect_edges(state: ImageState):\n",
    "    if state[\"verbose\"]:\n",
    "        print(\"🔗 Detecting edges...\")\n",
    "    detector.detect_edges()\n",
    "    return {}\n",
    "\n",
    "def create_graph(state: ImageState):\n",
    "    if state[\"verbose\"]:\n",
    "        print(\"📊 Creating graph...\")\n",
    "    return {\"graph\": detector.get_graph()}\n",
    "\n",
    "def validate_edges(state: ImageState):\n",
    "    if state[\"verbose\"]:\n",
    "        print(\"✅ Validating edges...\")\n",
    "    validator = EdgeValidator.from_json_file(from_root(\"datasets/test/json/4.json\"), detector.get_graph().edges)\n",
    "    return {\"validation_results\": validator.validate()}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Graph ===\n",
    "graph = StateGraph(ImageState)\n",
    "graph.add_node(\"read_image\", read_image)\n",
    "graph.add_node(\"classify_image\", classify_image)\n",
    "graph.add_node(\"handle_non_diagram\", handle_non_diagram)\n",
    "graph.add_node(\"run_yolo_detection\", run_yolo_detection)\n",
    "graph.add_node(\"crop_diagram\", crop_diagram)\n",
    "graph.add_node(\"detect_nodes\", detect_nodes)\n",
    "graph.add_node(\"detect_edges\", detect_edges)\n",
    "graph.add_node(\"create_graph\", create_graph)\n",
    "graph.add_node(\"validate_edges\", validate_edges)\n",
    "\n",
    "graph.add_edge(START, \"read_image\")\n",
    "graph.add_edge(\"read_image\", \"classify_image\")\n",
    "graph.add_conditional_edges(\"classify_image\", route_decision, {\n",
    "    \"run_yolo_detection\": \"run_yolo_detection\",\n",
    "    \"handle_non_diagram\": \"handle_non_diagram\"\n",
    "})\n",
    "graph.add_edge(\"run_yolo_detection\", \"crop_diagram\")\n",
    "graph.add_edge(\"crop_diagram\", \"detect_nodes\")\n",
    "graph.add_edge(\"detect_nodes\", \"detect_edges\")\n",
    "graph.add_edge(\"detect_edges\", \"create_graph\")\n",
    "graph.add_edge(\"create_graph\", \"validate_edges\")\n",
    "graph.add_edge(\"validate_edges\", END)\n",
    "graph.add_edge(\"handle_non_diagram\", END)\n",
    "\n",
    "compiled_graph = graph.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔍 Reading image: /Users/emilstausbol/Documents/GitHub/AIML25-Exam/datasets/test/images/4.png\n",
      "🧠 Image classification: Diagram (confidence: 0.64)\n",
      "📦 Running YOLO detection...\n",
      "\n",
      "image 1/1 /Users/emilstausbol/Documents/GitHub/AIML25-Exam/datasets/test/images/4.png: 384x640 7 sub-flows, 969.0ms\n",
      "Speed: 6.6ms preprocess, 969.0ms inference, 10.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "✂️ Cropping diagram parts...\n",
      "💾 Saved: tmp/cropped_1.png\n",
      "💾 Saved: tmp/cropped_2.png\n",
      "💾 Saved: tmp/cropped_3.png\n",
      "💾 Saved: tmp/cropped_4.png\n",
      "💾 Saved: tmp/cropped_5.png\n",
      "💾 Saved: tmp/cropped_6.png\n",
      "💾 Saved: tmp/cropped_7.png\n",
      "🔍 Detecting nodes...\n",
      "\n",
      "image 1/1 /Users/emilstausbol/Documents/GitHub/AIML25-Exam/datasets/test/images/4.png: 384x640 7 sub-flows, 900.6ms\n",
      "Speed: 1.9ms preprocess, 900.6ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "totale images: 7\n",
      "🔗 Detecting edges...\n"
     ]
    },
    {
     "ename": "InstructorRetryException",
     "evalue": "1 validation error for EdgeResponse\n  Input should be an object [type=model_type, input_value=[3], input_type=list]\n    For further information visit https://errors.pydantic.dev/2.11/v/model_type",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValidationError\u001b[39m                           Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/aiml25-exam/lib/python3.12/site-packages/instructor/retry.py:191\u001b[39m, in \u001b[36mretry_sync\u001b[39m\u001b[34m(func, response_model, args, kwargs, context, max_retries, strict, mode, hooks)\u001b[39m\n\u001b[32m    185\u001b[39m                 kwargs = handle_reask_kwargs(\n\u001b[32m    186\u001b[39m                     kwargs=kwargs,\n\u001b[32m    187\u001b[39m                     mode=mode,\n\u001b[32m    188\u001b[39m                     response=response,\n\u001b[32m    189\u001b[39m                     exception=e,\n\u001b[32m    190\u001b[39m                 )\n\u001b[32m--> \u001b[39m\u001b[32m191\u001b[39m                 \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[32m    192\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m RetryError \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/aiml25-exam/lib/python3.12/site-packages/instructor/retry.py:174\u001b[39m, in \u001b[36mretry_sync\u001b[39m\u001b[34m(func, response_model, args, kwargs, context, max_retries, strict, mode, hooks)\u001b[39m\n\u001b[32m    170\u001b[39m     response = update_total_usage(\n\u001b[32m    171\u001b[39m         response=response, total_usage=total_usage\n\u001b[32m    172\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m174\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mprocess_response\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore\u001b[39;49;00m\n\u001b[32m    175\u001b[39m \u001b[43m        \u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m=\u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    176\u001b[39m \u001b[43m        \u001b[49m\u001b[43mresponse_model\u001b[49m\u001b[43m=\u001b[49m\u001b[43mresponse_model\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    177\u001b[39m \u001b[43m        \u001b[49m\u001b[43mvalidation_context\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    178\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstrict\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstrict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    179\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    180\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    181\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    182\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m (ValidationError, JSONDecodeError) \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/aiml25-exam/lib/python3.12/site-packages/instructor/process_response.py:172\u001b[39m, in \u001b[36mprocess_response\u001b[39m\u001b[34m(response, response_model, stream, validation_context, strict, mode)\u001b[39m\n\u001b[32m    170\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m model\n\u001b[32m--> \u001b[39m\u001b[32m172\u001b[39m model = \u001b[43mresponse_model\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfrom_response\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    173\u001b[39m \u001b[43m    \u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    174\u001b[39m \u001b[43m    \u001b[49m\u001b[43mvalidation_context\u001b[49m\u001b[43m=\u001b[49m\u001b[43mvalidation_context\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    175\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstrict\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstrict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    176\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    177\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    179\u001b[39m \u001b[38;5;66;03m# ? This really hints at the fact that we need a better way of\u001b[39;00m\n\u001b[32m    180\u001b[39m \u001b[38;5;66;03m# ? attaching usage data and the raw response to the model we return.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/aiml25-exam/lib/python3.12/site-packages/instructor/function_calls.py:270\u001b[39m, in \u001b[36mOpenAISchema.from_response\u001b[39m\u001b[34m(cls, completion, validation_context, strict, mode)\u001b[39m\n\u001b[32m    260\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m mode \u001b[38;5;129;01min\u001b[39;00m {\n\u001b[32m    261\u001b[39m     Mode.JSON,\n\u001b[32m    262\u001b[39m     Mode.JSON_SCHEMA,\n\u001b[32m   (...)\u001b[39m\u001b[32m    268\u001b[39m     Mode.OPENROUTER_STRUCTURED_OUTPUTS,\n\u001b[32m    269\u001b[39m }:\n\u001b[32m--> \u001b[39m\u001b[32m270\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mparse_json\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcompletion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_context\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstrict\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    272\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mInvalid patch mode: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmode\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/aiml25-exam/lib/python3.12/site-packages/instructor/function_calls.py:574\u001b[39m, in \u001b[36mOpenAISchema.parse_json\u001b[39m\u001b[34m(cls, completion, validation_context, strict)\u001b[39m\n\u001b[32m    573\u001b[39m \u001b[38;5;66;03m# Validate the model from the JSON\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m574\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_validate_model_from_json\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mjson_content\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_context\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstrict\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/aiml25-exam/lib/python3.12/site-packages/instructor/function_calls.py:83\u001b[39m, in \u001b[36m_validate_model_from_json\u001b[39m\u001b[34m(cls, json_str, validation_context, strict)\u001b[39m\n\u001b[32m     82\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m strict:\n\u001b[32m---> \u001b[39m\u001b[32m83\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmodel_validate_json\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     84\u001b[39m \u001b[43m        \u001b[49m\u001b[43mjson_str\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m=\u001b[49m\u001b[43mvalidation_context\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstrict\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\n\u001b[32m     85\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     86\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     87\u001b[39m     \u001b[38;5;66;03m# Allow control characters\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/aiml25-exam/lib/python3.12/site-packages/pydantic/main.py:744\u001b[39m, in \u001b[36mBaseModel.model_validate_json\u001b[39m\u001b[34m(cls, json_data, strict, context, by_alias, by_name)\u001b[39m\n\u001b[32m    739\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m PydanticUserError(\n\u001b[32m    740\u001b[39m         \u001b[33m'\u001b[39m\u001b[33mAt least one of `by_alias` or `by_name` must be set to True.\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m    741\u001b[39m         code=\u001b[33m'\u001b[39m\u001b[33mvalidate-by-alias-and-name-false\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m    742\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m744\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m__pydantic_validator__\u001b[49m\u001b[43m.\u001b[49m\u001b[43mvalidate_json\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    745\u001b[39m \u001b[43m    \u001b[49m\u001b[43mjson_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstrict\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstrict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mby_alias\u001b[49m\u001b[43m=\u001b[49m\u001b[43mby_alias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mby_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43mby_name\u001b[49m\n\u001b[32m    746\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mValidationError\u001b[39m: 1 validation error for EdgeResponse\n  Input should be an object [type=model_type, input_value=[3], input_type=list]\n    For further information visit https://errors.pydantic.dev/2.11/v/model_type",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mRetryError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/aiml25-exam/lib/python3.12/site-packages/instructor/retry.py:163\u001b[39m, in \u001b[36mretry_sync\u001b[39m\u001b[34m(func, response_model, args, kwargs, context, max_retries, strict, mode, hooks)\u001b[39m\n\u001b[32m    162\u001b[39m response = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m163\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mattempt\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mmax_retries\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m    164\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mwith\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mattempt\u001b[49m\u001b[43m:\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/aiml25-exam/lib/python3.12/site-packages/tenacity/__init__.py:445\u001b[39m, in \u001b[36mBaseRetrying.__iter__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    444\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m445\u001b[39m     do = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43miter\u001b[49m\u001b[43m(\u001b[49m\u001b[43mretry_state\u001b[49m\u001b[43m=\u001b[49m\u001b[43mretry_state\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    446\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(do, DoAttempt):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/aiml25-exam/lib/python3.12/site-packages/tenacity/__init__.py:378\u001b[39m, in \u001b[36mBaseRetrying.iter\u001b[39m\u001b[34m(self, retry_state)\u001b[39m\n\u001b[32m    377\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m action \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.iter_state.actions:\n\u001b[32m--> \u001b[39m\u001b[32m378\u001b[39m     result = \u001b[43maction\u001b[49m\u001b[43m(\u001b[49m\u001b[43mretry_state\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    379\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/aiml25-exam/lib/python3.12/site-packages/tenacity/__init__.py:421\u001b[39m, in \u001b[36mBaseRetrying._post_stop_check_actions.<locals>.exc_check\u001b[39m\u001b[34m(rs)\u001b[39m\n\u001b[32m    420\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m retry_exc.reraise()\n\u001b[32m--> \u001b[39m\u001b[32m421\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m retry_exc \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mfut\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mexception\u001b[39;00m()\n",
      "\u001b[31mRetryError\u001b[39m: RetryError[<Future at 0x313351d60 state=finished raised ValidationError>]",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mInstructorRetryException\u001b[39m                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[180]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      2\u001b[39m image_path = \u001b[38;5;28mstr\u001b[39m(from_root(\u001b[33m\"\u001b[39m\u001b[33mdatasets/test/images/4.png\u001b[39m\u001b[33m\"\u001b[39m))\n\u001b[32m      3\u001b[39m initial_state = {\u001b[33m\"\u001b[39m\u001b[33mimage_path\u001b[39m\u001b[33m\"\u001b[39m: image_path, \u001b[33m\"\u001b[39m\u001b[33mverbose\u001b[39m\u001b[33m\"\u001b[39m: \u001b[38;5;28;01mTrue\u001b[39;00m}\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m result = \u001b[43mcompiled_graph\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43minitial_state\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      6\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m📦 Final state:\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      7\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m result.items():\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/aiml25-exam/lib/python3.12/site-packages/langgraph/pregel/__init__.py:2739\u001b[39m, in \u001b[36mPregel.invoke\u001b[39m\u001b[34m(self, input, config, stream_mode, output_keys, interrupt_before, interrupt_after, checkpoint_during, debug, **kwargs)\u001b[39m\n\u001b[32m   2737\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   2738\u001b[39m     chunks = []\n\u001b[32m-> \u001b[39m\u001b[32m2739\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2740\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   2741\u001b[39m \u001b[43m    \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2742\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2743\u001b[39m \u001b[43m    \u001b[49m\u001b[43moutput_keys\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_keys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2744\u001b[39m \u001b[43m    \u001b[49m\u001b[43minterrupt_before\u001b[49m\u001b[43m=\u001b[49m\u001b[43minterrupt_before\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2745\u001b[39m \u001b[43m    \u001b[49m\u001b[43minterrupt_after\u001b[49m\u001b[43m=\u001b[49m\u001b[43minterrupt_after\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2746\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcheckpoint_during\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcheckpoint_during\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2747\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdebug\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdebug\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2748\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2749\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m   2750\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[43m \u001b[49m\u001b[43m==\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mvalues\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\n\u001b[32m   2751\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlatest\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/aiml25-exam/lib/python3.12/site-packages/langgraph/pregel/__init__.py:2377\u001b[39m, in \u001b[36mPregel.stream\u001b[39m\u001b[34m(self, input, config, stream_mode, output_keys, interrupt_before, interrupt_after, checkpoint_during, debug, subgraphs)\u001b[39m\n\u001b[32m   2371\u001b[39m     \u001b[38;5;66;03m# Similarly to Bulk Synchronous Parallel / Pregel model\u001b[39;00m\n\u001b[32m   2372\u001b[39m     \u001b[38;5;66;03m# computation proceeds in steps, while there are channel updates.\u001b[39;00m\n\u001b[32m   2373\u001b[39m     \u001b[38;5;66;03m# Channel updates from step N are only visible in step N+1\u001b[39;00m\n\u001b[32m   2374\u001b[39m     \u001b[38;5;66;03m# channels are guaranteed to be immutable for the duration of the step,\u001b[39;00m\n\u001b[32m   2375\u001b[39m     \u001b[38;5;66;03m# with channel updates applied only at the transition between steps.\u001b[39;00m\n\u001b[32m   2376\u001b[39m     \u001b[38;5;28;01mwhile\u001b[39;00m loop.tick(input_keys=\u001b[38;5;28mself\u001b[39m.input_channels):\n\u001b[32m-> \u001b[39m\u001b[32m2377\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m_\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrunner\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtick\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2378\u001b[39m \u001b[43m            \u001b[49m\u001b[43mloop\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtasks\u001b[49m\u001b[43m.\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2379\u001b[39m \u001b[43m            \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mstep_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2380\u001b[39m \u001b[43m            \u001b[49m\u001b[43mretry_policy\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mretry_policy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2381\u001b[39m \u001b[43m            \u001b[49m\u001b[43mget_waiter\u001b[49m\u001b[43m=\u001b[49m\u001b[43mget_waiter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2382\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m   2383\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;66;43;03m# emit output\u001b[39;49;00m\n\u001b[32m   2384\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01myield from\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43moutput\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2385\u001b[39m \u001b[38;5;66;03m# emit output\u001b[39;00m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[178]\u001b[39m\u001b[32m, line 66\u001b[39m, in \u001b[36mdetect_edges\u001b[39m\u001b[34m(state)\u001b[39m\n\u001b[32m     64\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m state[\u001b[33m\"\u001b[39m\u001b[33mverbose\u001b[39m\u001b[33m\"\u001b[39m]:\n\u001b[32m     65\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m🔗 Detecting edges...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m66\u001b[39m \u001b[43mdetector\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdetect_edges\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     67\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m {}\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/GitHub/AIML25-Exam/src/llm_detector.py:173\u001b[39m, in \u001b[36mDetector.detect_edges\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    171\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mdetect_edges\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m    172\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m graph_image \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.graph_images:\n\u001b[32m--> \u001b[39m\u001b[32m173\u001b[39m         response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43medge_detector\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    174\u001b[39m \u001b[43m            \u001b[49m\u001b[43mgraph_image\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mimage\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgraph_image\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mnodes\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    175\u001b[39m         graph_image[\u001b[33m\"\u001b[39m\u001b[33medges\u001b[39m\u001b[33m\"\u001b[39m] = [\n\u001b[32m    176\u001b[39m             Edge(edge[\u001b[33m\"\u001b[39m\u001b[33msource\u001b[39m\u001b[33m\"\u001b[39m], edge[\u001b[33m\"\u001b[39m\u001b[33mtarget\u001b[39m\u001b[33m\"\u001b[39m]) \u001b[38;5;28;01mfor\u001b[39;00m edge \u001b[38;5;129;01min\u001b[39;00m response.answer]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/GitHub/AIML25-Exam/src/llm_detector.py:143\u001b[39m, in \u001b[36mEdgeDetector.invoke\u001b[39m\u001b[34m(self, image, nodes)\u001b[39m\n\u001b[32m    142\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34minvoke\u001b[39m(\u001b[38;5;28mself\u001b[39m, image: Image.Image, nodes: List[Node]):\n\u001b[32m--> \u001b[39m\u001b[32m143\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[43m{\u001b[49m\n\u001b[32m    144\u001b[39m \u001b[43m        \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrole\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43muser\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    145\u001b[39m \u001b[43m        \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcontent\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mprepare_prompt\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mnode\u001b[49m\u001b[43m.\u001b[49m\u001b[43mid\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mnode\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mnodes\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mprepare_image_content\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\n\u001b[32m    146\u001b[39m \u001b[43m    \u001b[49m\u001b[43m}\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse_model\u001b[49m\u001b[43m=\u001b[49m\u001b[43mEdgeResponse\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/GitHub/AIML25-Exam/src/llm_caller.py:88\u001b[39m, in \u001b[36mLLMCaller.invoke\u001b[39m\u001b[34m(self, messages, response_model, **kwargs)\u001b[39m\n\u001b[32m     74\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34minvoke\u001b[39m(\n\u001b[32m     75\u001b[39m     \u001b[38;5;28mself\u001b[39m, messages: List[Message], response_model: ResponseType = BaseResponse, **kwargs\n\u001b[32m     76\u001b[39m ) -> ResponseType:\n\u001b[32m     77\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Sends a prompt to the LLM and retrieves a structured response.\u001b[39;00m\n\u001b[32m     78\u001b[39m \n\u001b[32m     79\u001b[39m \u001b[33;03m    Args:\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     86\u001b[39m \u001b[33;03m        ResponseType: The structured response from the LLM, parsed into the specified response model.\u001b[39;00m\n\u001b[32m     87\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m88\u001b[39m     response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mclient\u001b[49m\u001b[43m.\u001b[49m\u001b[43mchat\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcompletions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     89\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmodel_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     90\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     91\u001b[39m \u001b[43m        \u001b[49m\u001b[43mproject_id\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mproject_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     92\u001b[39m \u001b[43m        \u001b[49m\u001b[43mapikey\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mapi_key\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     93\u001b[39m \u001b[43m        \u001b[49m\u001b[43mapi_base\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mapi_url\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     94\u001b[39m \u001b[43m        \u001b[49m\u001b[43mresponse_model\u001b[49m\u001b[43m=\u001b[49m\u001b[43mresponse_model\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     95\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     96\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     97\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/aiml25-exam/lib/python3.12/site-packages/instructor/client.py:180\u001b[39m, in \u001b[36mInstructor.create\u001b[39m\u001b[34m(self, response_model, messages, max_retries, validation_context, context, strict, **kwargs)\u001b[39m\n\u001b[32m    168\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcreate\u001b[39m(\n\u001b[32m    169\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    170\u001b[39m     response_model: \u001b[38;5;28mtype\u001b[39m[T] | \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    176\u001b[39m     **kwargs: Any,\n\u001b[32m    177\u001b[39m ) -> T | Any | Awaitable[T] | Awaitable[Any]:\n\u001b[32m    178\u001b[39m     kwargs = \u001b[38;5;28mself\u001b[39m.handle_kwargs(kwargs)\n\u001b[32m--> \u001b[39m\u001b[32m180\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcreate_fn\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    181\u001b[39m \u001b[43m        \u001b[49m\u001b[43mresponse_model\u001b[49m\u001b[43m=\u001b[49m\u001b[43mresponse_model\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    182\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    183\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmax_retries\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmax_retries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    184\u001b[39m \u001b[43m        \u001b[49m\u001b[43mvalidation_context\u001b[49m\u001b[43m=\u001b[49m\u001b[43mvalidation_context\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    185\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    186\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstrict\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstrict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    187\u001b[39m \u001b[43m        \u001b[49m\u001b[43mhooks\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mhooks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    188\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    189\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/aiml25-exam/lib/python3.12/site-packages/instructor/patch.py:193\u001b[39m, in \u001b[36mpatch.<locals>.new_create_sync\u001b[39m\u001b[34m(response_model, validation_context, context, max_retries, strict, hooks, *args, **kwargs)\u001b[39m\n\u001b[32m    187\u001b[39m response_model, new_kwargs = handle_response_model(\n\u001b[32m    188\u001b[39m     response_model=response_model, mode=mode, **kwargs\n\u001b[32m    189\u001b[39m )  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[32m    191\u001b[39m new_kwargs = handle_templating(new_kwargs, mode=mode, context=context)\n\u001b[32m--> \u001b[39m\u001b[32m193\u001b[39m response = \u001b[43mretry_sync\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    194\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore\u001b[39;49;00m\n\u001b[32m    195\u001b[39m \u001b[43m    \u001b[49m\u001b[43mresponse_model\u001b[49m\u001b[43m=\u001b[49m\u001b[43mresponse_model\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    196\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    197\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmax_retries\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmax_retries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    198\u001b[39m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[43m=\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    199\u001b[39m \u001b[43m    \u001b[49m\u001b[43mhooks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhooks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    200\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstrict\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstrict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    201\u001b[39m \u001b[43m    \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnew_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    202\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    203\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    204\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/aiml25-exam/lib/python3.12/site-packages/instructor/retry.py:194\u001b[39m, in \u001b[36mretry_sync\u001b[39m\u001b[34m(func, response_model, args, kwargs, context, max_retries, strict, mode, hooks)\u001b[39m\n\u001b[32m    192\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m RetryError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    193\u001b[39m     logger.debug(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mRetry error: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m194\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m InstructorRetryException(\n\u001b[32m    195\u001b[39m         e.last_attempt._exception,\n\u001b[32m    196\u001b[39m         last_completion=response,\n\u001b[32m    197\u001b[39m         n_attempts=attempt.retry_state.attempt_number,\n\u001b[32m    198\u001b[39m         \u001b[38;5;66;03m#! deprecate messages soon\u001b[39;00m\n\u001b[32m    199\u001b[39m         messages=extract_messages(\n\u001b[32m    200\u001b[39m             kwargs\n\u001b[32m    201\u001b[39m         ),  \u001b[38;5;66;03m# Use the optimized function instead of nested lookups\u001b[39;00m\n\u001b[32m    202\u001b[39m         create_kwargs=kwargs,\n\u001b[32m    203\u001b[39m         total_usage=total_usage,\n\u001b[32m    204\u001b[39m     ) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01me\u001b[39;00m\n",
      "\u001b[31mInstructorRetryException\u001b[39m: 1 validation error for EdgeResponse\n  Input should be an object [type=model_type, input_value=[3], input_type=list]\n    For further information visit https://errors.pydantic.dev/2.11/v/model_type",
      "During task with name 'detect_edges' and id 'b0731bb8-c028-5711-d0aa-a0d7852b2675'"
     ]
    }
   ],
   "source": [
    "# === Run ===\n",
    "image_path = str(from_root(\"datasets/test/images/4.png\"))\n",
    "initial_state = {\"image_path\": image_path, \"verbose\": True}\n",
    "result = compiled_graph.invoke(initial_state)\n",
    "\n",
    "print(\"\\n📦 Final state:\")\n",
    "for k, v in result.items():\n",
    "    if isinstance(v, list):\n",
    "        print(f\"- {k}: {len(v)} items\")\n",
    "    else:\n",
    "        print(f\"- {k}: {v}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_image_with_boxes(image_path, detections):\n",
    "    import matplotlib.pyplot as plt\n",
    "    import matplotlib.patches as patches\n",
    "    image = Image.open(image_path).convert(\"RGB\")\n",
    "    fig, ax = plt.subplots(figsize=(12, 8))\n",
    "    ax.imshow(image)\n",
    "    for det in detections:\n",
    "        x1, y1, x2, y2 = det[\"coords\"]\n",
    "        rect = patches.Rectangle((x1, y1), x2 - x1, y2 - y1, linewidth=2, edgecolor='r', facecolor='none')\n",
    "        ax.add_patch(rect)\n",
    "        ax.text(x1, y1 - 5, f\"{det['label']} ({det['confidence']:.2f})\", color='white', backgroundcolor='red')\n",
    "    plt.axis(\"off\")\n",
    "    plt.show()\n",
    "\n",
    "if result.get(\"is_diagram\") and \"diagram_detections\" in result:\n",
    "    show_image_with_boxes(image_path, result[\"diagram_detections\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /Users/emilstausbol/Documents/GitHub/AIML25-Exam/datasets/test/images/4.png: 384x640 7 sub-flows, 3893.4ms\n",
      "Speed: 10.1ms preprocess, 3893.4ms inference, 18.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "[{'xywh': [1380.986328125, 604.0886840820312, 989.7669677734375, 1017.4681396484375], 'confidence': 0.9350194334983826, 'class_id': 0, 'xyxy': [886.1029052734375, 95.35460662841797, 1875.869873046875, 1112.82275390625]}, {'xywh': [802.1484375, 599.476318359375, 809.3967895507812, 987.23681640625], 'confidence': 0.8156471848487854, 'class_id': 0, 'xyxy': [397.45001220703125, 105.8579330444336, 1206.8468017578125, 1093.0947265625]}, {'xywh': [634.4658813476562, 597.1973266601562, 1238.7115478515625, 993.0460815429688], 'confidence': 0.46774500608444214, 'class_id': 0, 'xyxy': [15.1101655960083, 100.67426300048828, 1253.8216552734375, 1093.7203369140625]}, {'xywh': [444.9051818847656, 602.0018310546875, 868.2406616210938, 1004.81494140625], 'confidence': 0.3852144181728363, 'class_id': 0, 'xyxy': [10.78487491607666, 99.59437561035156, 879.0255126953125, 1104.4093017578125]}, {'xywh': [1736.298828125, 759.9703369140625, 588.7703857421875, 609.4484252929688], 'confidence': 0.37004905939102173, 'class_id': 0, 'xyxy': [1441.9136962890625, 455.24615478515625, 2030.68408203125, 1064.694580078125]}, {'xywh': [893.116943359375, 486.6313171386719, 579.269287109375, 648.6555786132812], 'confidence': 0.36914703249931335, 'class_id': 0, 'xyxy': [603.4822998046875, 162.3035430908203, 1182.7515869140625, 810.9591064453125]}, {'xywh': [644.4774169921875, 636.7406005859375, 424.4251708984375, 865.884521484375], 'confidence': 0.2773652970790863, 'class_id': 0, 'xyxy': [432.26483154296875, 203.79837036132812, 856.6900024414062, 1069.682861328125]}]\n"
     ]
    }
   ],
   "source": [
    "# Optional: Show YOLO detections\n",
    "if result.get(\"is_diagram\") and result.get(\"diagram_detections\"):\n",
    "    def show_image_with_boxes(image_path, detections):\n",
    "        image = Image.open(image_path).convert(\"RGB\")\n",
    "        fig, ax = plt.subplots(figsize=(12, 8))\n",
    "        ax.imshow(image)\n",
    "        for det in detections:\n",
    "            x1, y1, x2, y2 = det[\"coords\"]\n",
    "            rect = patches.Rectangle((x1, y1), x2 - x1, y2 - y1, linewidth=2, edgecolor='r', facecolor='none')\n",
    "            ax.add_patch(rect)\n",
    "            ax.text(x1, y1 - 5, f\"{det['label']} ({det['confidence']:.2f})\", color='white', backgroundcolor='red')\n",
    "        plt.axis(\"off\")\n",
    "        plt.show()\n",
    "\n",
    "    show_image_with_boxes(result[\"image_path\"], result[\"diagram_detections\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aiml25-exam",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
