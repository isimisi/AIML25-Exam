{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a4e6b832",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working directory set to: /Users/isimisi/Documents/GitHub/isimisi/AIML25-Exam\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "while Path.cwd().name.lower() != \"aiml25-exam\" and \"aiml25-exam\" in str(Path.cwd()).lower():\n",
    "    os.chdir(\"..\")  # Move up one directory\n",
    "print(f\"Working directory set to: {Path.cwd()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "169933c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 1400x1000 with 0 Axes>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1400x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from src.yolo.yolo import Yolo\n",
    "from ultralytics import YOLO\n",
    "from src.utils.path import from_root\n",
    "from src.llm_caller import LLMCaller\n",
    "from src.llm_detector import Detector\n",
    "from src.mermaid_detector import MermaidDetector\n",
    "from src.mermaid_to_json import MermaidToJSON\n",
    "from src.edge_validator import EdgeValidator\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "plt.figure(figsize=(14, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d3c64ebb",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = YOLO(from_root(\"models/yolo-trained.pt\"))\n",
    "\n",
    "yolo = Yolo(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b0c885b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from decouple import config\n",
    "\n",
    "# WX_API_KEY = config(\"WX_API_KEY\")\n",
    "# WX_PROJECT_ID = config(\"WX_PROJECT_ID\")\n",
    "# WX_API_URL = \"https://us-south.ml.cloud.ibm.com\"\n",
    "OPENAI_KEY = config(\"OPENAI_API_KEY\")\n",
    "# OPENAI_API_URL = \"https://api.openai.com/v1\"\n",
    "# OPENAI_PROJECT = \"proj_6SmPVkyXa0GChFv7TmDjB9B5\"\n",
    "\n",
    "model = LLMCaller(\n",
    "    api_key=OPENAI_KEY,          \n",
    "    model_id=\"gpt-4o\",     \n",
    "    params={\n",
    "        \"temperature\": 0.7,\n",
    "        \"max_tokens\": 150\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b0919fdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "detector = Detector(model, yolo)\n",
    "mermaidDetector = MermaidDetector(model, yolo, MermaidToJSON(model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "55055e04",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mermaid_with_nodes_crop(path: str, json_path: str):\n",
    "    mermaidDetector.initiate_image(str(from_root(path)))\n",
    "    mermaidDetector.detect_nodes()\n",
    "    mermaidDetector.detect_edges()\n",
    "    mermaidDetector.convert_edges()\n",
    "    graph = mermaidDetector.get_graph()\n",
    "    validator = EdgeValidator.from_json_file(str(from_root(json_path)), graph.edges)\n",
    "    return validator.validate()\n",
    "\n",
    "def mermaid_crop(path: str, json_path: str):\n",
    "    mermaidDetector.initiate_image(str(from_root(path)))\n",
    "    mermaidDetector.detect_edges()\n",
    "    mermaidDetector.convert_edges()\n",
    "    graph = mermaidDetector.get_graph()\n",
    "    validator = EdgeValidator.from_json_file(str(from_root(json_path)), graph.edges)\n",
    "    return validator.validate()\n",
    "\n",
    "def mermaid_no_crop(path: str, json_path: str):\n",
    "    mermaidDetector.initiate_image(str(from_root(path)), should_crop=False)\n",
    "    mermaidDetector.detect_edges()\n",
    "    mermaidDetector.convert_edges()\n",
    "    graph = mermaidDetector.get_graph()\n",
    "    validator = EdgeValidator.from_json_file(str(from_root(json_path)), graph.edges)\n",
    "    return validator.validate()\n",
    "\n",
    "def mermaid_with_nodes_no_crop(path: str, json_path: str):\n",
    "    mermaidDetector.initiate_image(str(from_root(path)), should_crop=False)\n",
    "    mermaidDetector.detect_nodes()\n",
    "    mermaidDetector.detect_edges()\n",
    "    mermaidDetector.convert_edges()\n",
    "    graph = mermaidDetector.get_graph()\n",
    "    validator = EdgeValidator.from_json_file(str(from_root(json_path)), graph.edges)\n",
    "    return validator.validate()\n",
    "\n",
    "def with_nodes_crop(path: str, json_path: str):\n",
    "    detector.initiate_image(str(from_root(path)))\n",
    "    detector.detect_nodes()\n",
    "    detector.detect_edges()\n",
    "    graph = detector.get_graph()\n",
    "    validator = EdgeValidator.from_json_file(str(from_root(json_path)), graph.edges)\n",
    "    return validator.validate()\n",
    "\n",
    "def crop(path: str, json_path: str):\n",
    "    detector.initiate_image(str(from_root(path)))\n",
    "    detector.detect_edges()\n",
    "    graph = detector.get_graph()\n",
    "    validator = EdgeValidator.from_json_file(str(from_root(json_path)), graph.edges)\n",
    "    return validator.validate()\n",
    "\n",
    "def no_crop(path: str, json_path: str):\n",
    "    detector.initiate_image(str(from_root(path)), should_crop=False)\n",
    "    detector.detect_edges()\n",
    "    graph = detector.get_graph()\n",
    "    validator = EdgeValidator.from_json_file(str(from_root(json_path)), graph.edges)\n",
    "    return validator.validate()\n",
    "\n",
    "def with_nodes_no_crop(path: str, json_path: str):\n",
    "    detector.initiate_image(str(from_root(path)), should_crop=False)\n",
    "    detector.detect_nodes()\n",
    "    detector.detect_edges()\n",
    "    graph = detector.get_graph()\n",
    "    validator = EdgeValidator.from_json_file(str(from_root(json_path)), graph.edges)\n",
    "    return validator.validate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42df233d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = [\n",
    "    [\n",
    "        \"datasets/test/images/1.png\",\n",
    "        \"datasets/test/json/1.json\",\n",
    "    ],\n",
    "    [\n",
    "        \"datasets/test/images/3.png\",\n",
    "        \"datasets/test/json/3.json\",\n",
    "    ],\n",
    "    [\n",
    "        \"datasets/test/images/4.png\",\n",
    "        \"datasets/test/json/4.json\",\n",
    "    ],\n",
    "    [\n",
    "        \"datasets/test/images/5.png\",\n",
    "        \"datasets/test/json/5.json\",\n",
    "    ],\n",
    "    [\n",
    "        \"datasets/test/images/6.png\",\n",
    "        \"datasets/test/json/6.json\",\n",
    "    ],\n",
    "    [\n",
    "        \"datasets/test/images/7.png\",\n",
    "        \"datasets/test/json/7.json\",\n",
    "    ],\n",
    "    [\n",
    "        \"datasets/test/images/8.png\",\n",
    "        \"datasets/test/json/8.json\",\n",
    "    ],\n",
    "    [\n",
    "        \"datasets/test/images/9.png\",\n",
    "        \"datasets/test/json/9.json\",\n",
    "    ],\n",
    "    [\n",
    "        \"datasets/test/images/10.png\",\n",
    "        \"datasets/test/json/10.json\",\n",
    "    ],\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6e8441a",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = {\n",
    "    \"mermaid_no_crop\": {\n",
    "        \"precision\": [],\n",
    "        \"recall\": [],\n",
    "        \"f1_score\": []\n",
    "    },\n",
    "    \"mermaid_crop\": {\n",
    "        \"precision\": [],\n",
    "        \"recall\": [],\n",
    "        \"f1_score\": []\n",
    "    },\n",
    "    \"mermaid_with_nodes_no_crop\": {\n",
    "        \"precision\": [],\n",
    "        \"recall\": [],\n",
    "        \"f1_score\": []\n",
    "    },\n",
    "    \"mermaid_with_nodes_crop\": {\n",
    "        \"precision\": [],\n",
    "        \"recall\": [],\n",
    "        \"f1_score\": []\n",
    "    },\n",
    "    \"no_crop\": {\n",
    "        \"precision\": [],\n",
    "        \"recall\": [],\n",
    "        \"f1_score\": []\n",
    "    },\n",
    "    \"crop\": {\n",
    "        \"precision\": [],\n",
    "        \"recall\": [],\n",
    "        \"f1_score\": []\n",
    "    },\n",
    "    \"with_nodes_no_crop\": {\n",
    "        \"precision\": [],\n",
    "        \"recall\": [],\n",
    "        \"f1_score\": []\n",
    "    },\n",
    "    \"with_nodes_crop\": {\n",
    "        \"precision\": [],\n",
    "        \"recall\": [],\n",
    "        \"f1_score\": []\n",
    "    }\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6a5517c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def appendScores(val_scores: dict, fn: str):\n",
    "    s = scores[fn]\n",
    "    precision = val_scores[\"precision\"]\n",
    "    s[\"precision\"].append(precision)\n",
    "    f1_score = val_scores[\"f1_score\"]\n",
    "    s[\"f1_score\"].append(f1_score)\n",
    "    recall = val_scores[\"recall\"]\n",
    "    s[\"recall\"].append(recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "678039f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Isaac\n",
    "for [img_path, json_path] in dataset:\n",
    "    appendScores(mermaid_crop(img_path, json_path), \"mermaid_crop\")\n",
    "    appendScores(mermaid_with_nodes_crop(img_path, json_path), \"mermaid_with_nodes_crop\")\n",
    "    appendScores(mermaid_no_crop(img_path, json_path), \"mermaid_no_crop\")\n",
    "\n",
    "with open('isaac.json', 'w') as f:\n",
    "    json.dump(scores, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa88bc7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Emil\n",
    "for [img_path, json_path] in dataset:\n",
    "    appendScores(mermaid_with_nodes_no_crop(img_path, json_path), \"mermaid_with_nodes_no_crop\")\n",
    "    appendScores(crop(img_path, json_path), \"crop\")\n",
    "    appendScores(with_nodes_crop(img_path, json_path), \"with_nodes_crop\")\n",
    "\n",
    "with open('emil.json', 'w') as f:\n",
    "    json.dump(scores, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc583966",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simon\n",
    "for [img_path, json_path] in dataset:\n",
    "    appendScores(no_crop(img_path, json_path), \"no_crop\")\n",
    "    appendScores(with_nodes_no_crop(img_path, json_path), \"with_nodes_no_crop\")\n",
    "\n",
    "with open('simon.json', 'w') as f:\n",
    "    json.dump(scores, f, indent=4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aiml25-exam",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
